<script>
export default {
  data: () => ({
    show: true
  })
}
</script>

<template>
  <div id="eleventhPart" class="sectionMargin">
    <h2 class="sectionTitle">Deepfakes</h2>
    <div class="divided">
      <div class="midWidth">
        <h3>So we can spot some clues in a fake video. Most are in the face of the character and in the area between the chin and nose. “We can look for different things technically in these videos,” says Posters. “In the contours of parts of the face, such as blur marks, a blurred image or discoloration”. According to Cornell University also suggest that the eyes can be a sign that the video is a “deepfake”. Thus, the character would blink less. In a study published in 2018, the researchers used machine learning to analyse the opening and closing of the eyes. For this, they have developed a neural network to identify the speed at which people blink in videos. With fake videos, the subject often blinks much less than a real character. Indeed, we realize that the only way to fight an AI capable of modifying voice and face is to create another AI capable of verifying whether the content is truthful or not, we fight evil with evil as we say. Only it’s the game of the cat and the mouse, when the deepfakes become more efficient and the AIs detect how to untangle the real from the fake so the deepfakes creators look for more discreet ways and so on, it’s an endless loop.</h3>
        <br>
        <h3>Subsequently, hyper pornography appeared on the Internet in 2017, notably on Reddit13, and has since been banned by Reddit, Twitter, Pornhub and others. The problem with this kind of process is that it can become a means of pressure on people or a means of spreading rumors about people, whether they are famous or not. There are deepfakes similar to fake videos in politics except that this time women are mainly affected. Because for the people who create these fake videos, showing a naked woman is a way to humiliate her and thus make her lose her social value, to discredit her. Of course, deepfake porn can also be used for political purposes. This is what happened to Rana Ayyub in April 2018. Rana is an Indian journalist who has investigated corruption in her country. Until a fake porn directed at her was posted online to humiliate her and silence her. She had a breakdown. It is a scourge that is rampant and a significant number of women are affected, making them depressive and uncomfortable in their skin, all while these videos are obviously false. In January 2018, an application called FakeApp was launched that allows you to easily create videos where faces have been swapped and share them. Celebrities are the main targets of these fake sex videos, but some other people are also affected.</h3>
      </div>
      <div class="midWidth">
        <img src="../assets/img/rana.jpg" alt="">
      </div>
    </div>
  </div>
</template>

<style scoped>
.midWidth img {
  width: 70%;
  margin: 0 0 0 75px;
}
@media screen and (min-width: 1500px) and (max-width: 1700px) {
  .midWidth img {
    margin: 75px 0 0 75px;
  }
}
</style>
